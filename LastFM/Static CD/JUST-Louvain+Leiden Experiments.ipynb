{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Analysis of Static Community Detection Using JUST\n",
    "\n",
    "Running both the Louvain and Leiden algorithms multiple times and recording various statistics for each run can provide valuable insights for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Edge List w/ Weights to NetworkX\n",
    "\n",
    "NetworkX's read_weighted_edgelist function expects a simple text file with lines of the form <node1> <node2> <weight>, without headers. Since our data is in CSV format, you'll need to use Pandas (or another method) to load the CSV and adjust it to become readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source  target    weight\n",
      "0          u_2    a_51  0.999056\n",
      "1          u_2    a_52  0.944903\n",
      "2          u_2    a_53  0.992538\n",
      "3          u_2    a_54  0.692012\n",
      "4          u_2    a_55  0.999549\n",
      "...        ...     ...       ...\n",
      "160877  u_2099  u_1801  0.996204\n",
      "160878  u_2099  u_2006  0.996046\n",
      "160879  u_2099  u_2016  0.996104\n",
      "160880  u_2100   u_586  0.998411\n",
      "160881  u_2100   u_607  0.998568\n",
      "\n",
      "[160882 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edge_list_df = pd.read_csv('New Input/JUST_edge_list_with_similarity.csv')\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges with negative weights: 17409\n"
     ]
    }
   ],
   "source": [
    "negative_weights = edge_list_df[edge_list_df['weight'] < 0]\n",
    "print(f\"Number of edges with negative weights: {len(negative_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Louvain is not made to consider negative edge weights, we will rescale the weights such that instead of [-1, 1] being the range, it is now [0, 1], where 0 now represents perfect dissimilarity, 0.5 represents orthogonality, and 1 represents perfect similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source  target    weight\n",
      "0          u_2    a_51  0.999528\n",
      "1          u_2    a_52  0.972451\n",
      "2          u_2    a_53  0.996269\n",
      "3          u_2    a_54  0.846006\n",
      "4          u_2    a_55  0.999775\n",
      "...        ...     ...       ...\n",
      "160877  u_2099  u_1801  0.998102\n",
      "160878  u_2099  u_2006  0.998023\n",
      "160879  u_2099  u_2016  0.998052\n",
      "160880  u_2100   u_586  0.999206\n",
      "160881  u_2100   u_607  0.999284\n",
      "\n",
      "[160882 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "edge_list_df['weight'] = (edge_list_df['weight'] + 1) / 2\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the creation of a graph, NetworkX specifies that an undirected, weighted graph must not have self-loop, parallel edges (A->B, B->A), or duplicate edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate edges: 0\n",
      "Number of self-loops: 0\n",
      "source    0\n",
      "target    0\n",
      "weight    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "print(f\"Number of duplicate edges: {duplicate_edges.sum()}\")\n",
    "\n",
    "self_loops = edge_list_df[edge_list_df['source'] == edge_list_df['target']]\n",
    "print(f\"Number of self-loops: {len(self_loops)}\")\n",
    "\n",
    "print(edge_list_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [source, target, weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate edges (ignoring the weight column)\n",
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "\n",
    "# Filter to get only the duplicate edges\n",
    "parallel_edges_df = edge_list_df[duplicate_edges]\n",
    "\n",
    "# Sort to better visualize parallel edges\n",
    "parallel_edges_sorted = parallel_edges_df.sort_values(by=['source', 'target'])\n",
    "\n",
    "print(parallel_edges_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Undirected Weighted NX Graph\n",
    "\n",
    "We iterate over the edge list DataFrame rows to add edges along with their weights to a new NetworkX graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_graph_info(graph):\n",
    "    print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"Number of edges:\", graph.number_of_edges())\n",
    "    \n",
    "    # Checking the graph type to provide appropriate information\n",
    "    if isinstance(graph, nx.DiGraph):\n",
    "        print(\"Graph is Directed\")\n",
    "    else:\n",
    "        print(\"Graph is Undirected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new graph\n",
    "G = nx.MultiGraph()\n",
    "\n",
    "# Add edges and weights\n",
    "for index, row in edge_list_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    weight = row['weight']\n",
    "    \n",
    "    # Add the edge with weight\n",
    "    G.add_edge(source, target, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 21518\n",
      "Number of edges: 160882\n",
      "Graph is Undirected\n"
     ]
    }
   ],
   "source": [
    "get_graph_info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Modularity, Run Time and No. of Communities\n",
    "\n",
    "- Iterates 10 times, running both the Louvain and Leiden using CDLib algorithms on each iteration.\n",
    "- Records modularity, number of communities, and execution time for each run.\n",
    "- Calculates the average modularity, average number of communities, and average execution time for both algorithms across all runs.\n",
    "- Stores all this information in the results dictionary for easy access and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'bayanpy', 'infomap', 'wurlitzer'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw', 'pyclustering'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "from cdlib import algorithms\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data structure for results\n",
    "results = {\n",
    "    \"Louvain\": {\"modularity\": [], \"communities\": [], \"time\": []},\n",
    "    \"Leiden\": {\"modularity\": [], \"communities\": [], \"time\": []}\n",
    "}\n",
    "\n",
    "# Execute each algorithm 10 times\n",
    "for _ in range(10):\n",
    "    # Louvain\n",
    "    start_time = time.time()\n",
    "    communities_louvain = algorithms.louvain(G, weight='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Louvain\"][\"modularity\"].append(communities_louvain.newman_girvan_modularity().score)\n",
    "    results[\"Louvain\"][\"communities\"].append(len(communities_louvain.communities))\n",
    "    results[\"Louvain\"][\"time\"].append(elapsed_time)\n",
    "    \n",
    "    # Leiden\n",
    "    start_time = time.time()\n",
    "    communities_leiden = algorithms.leiden(G, weights='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Leiden\"][\"modularity\"].append(communities_leiden.newman_girvan_modularity().score)\n",
    "    results[\"Leiden\"][\"communities\"].append(len(communities_leiden.communities))\n",
    "    results[\"Leiden\"][\"time\"].append(elapsed_time)\n",
    "\n",
    "# Calculate averages\n",
    "for method in results:\n",
    "    results[method][\"avg_modularity\"] = np.mean(results[method][\"modularity\"])\n",
    "    results[method][\"avg_time\"] = np.mean(results[method][\"time\"])\n",
    "    results[method][\"avg_communities\"] = np.mean(results[method][\"communities\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Louvain': {'modularity': [0.48787245174148963, 0.4875821610607214, 0.4798222465884821, 0.4849485185003455, 0.4826929309229858, 0.4623715573684709, 0.5085587918735801, 0.47969852009227737, 0.4917758562218015, 0.4767517403654994], 'communities': [561, 533, 594, 575, 549, 639, 15, 571, 562, 625], 'time': [10.978015899658203, 13.526695966720581, 13.75668478012085, 10.96618914604187, 12.305590867996216, 13.670734882354736, 11.65299916267395, 10.841839075088501, 8.893937826156616, 12.886661291122437], 'avg_modularity': 0.48420747747356535, 'avg_time': 11.947934889793396, 'avg_communities': 522.4}, 'Leiden': {'modularity': [0.5141272181100943, 0.5171112572122496, 0.5177108822604298, 0.5113865530975705, 0.5171342734585987, 0.5135731165599291, 0.5136714602877601, 0.5163515187791415, 0.5132695249597226, 0.517785317101375], 'communities': [15, 16, 12, 14, 14, 14, 19, 15, 16, 14], 'time': [3.9380009174346924, 3.358065128326416, 2.926163911819458, 3.0199339389801025, 3.1228387355804443, 2.962183952331543, 2.931429147720337, 3.230976104736328, 3.00992488861084, 3.1872410774230957], 'avg_modularity': 0.5152121121826873, 'avg_time': 3.1686757802963257, 'avg_communities': 14.9}}\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Algorithm  Run  Modularity  Communities   Time (s)\n",
      "0    Louvain    1    0.487872          561  10.978016\n",
      "1    Louvain    2    0.487582          533  13.526696\n",
      "2    Louvain    3    0.479822          594  13.756685\n",
      "3    Louvain    4    0.484949          575  10.966189\n",
      "4    Louvain    5    0.482693          549  12.305591\n",
      "5    Louvain    6    0.462372          639  13.670735\n",
      "6    Louvain    7    0.508559           15  11.652999\n",
      "7    Louvain    8    0.479699          571  10.841839\n",
      "8    Louvain    9    0.491776          562   8.893938\n",
      "9    Louvain   10    0.476752          625  12.886661\n",
      "10    Leiden    1    0.514127           15   3.938001\n",
      "11    Leiden    2    0.517111           16   3.358065\n",
      "12    Leiden    3    0.517711           12   2.926164\n",
      "13    Leiden    4    0.511387           14   3.019934\n",
      "14    Leiden    5    0.517134           14   3.122839\n",
      "15    Leiden    6    0.513573           14   2.962184\n",
      "16    Leiden    7    0.513671           19   2.931429\n",
      "17    Leiden    8    0.516352           15   3.230976\n",
      "18    Leiden    9    0.513270           16   3.009925\n",
      "19    Leiden   10    0.517785           14   3.187241\n",
      "  Algorithm  Avg. Modularity  Avg. Communities  Avg. Time (s)\n",
      "0   Louvain         0.484207             522.4      11.947935\n",
      "1    Leiden         0.515212              14.9       3.168676\n"
     ]
    }
   ],
   "source": [
    "# Convert the results dictionary into a pandas DataFrame\n",
    "# First, prepare the data in a structured form\n",
    "data = {\n",
    "    \"Algorithm\": [],\n",
    "    \"Run\": [],\n",
    "    \"Modularity\": [],\n",
    "    \"Communities\": [],\n",
    "    \"Time (s)\": []\n",
    "}\n",
    "\n",
    "# Populate the structured data from the results\n",
    "for algo in results:\n",
    "    for run in range(10):  # Assuming 10 runs as previously set\n",
    "        data[\"Algorithm\"].append(algo)\n",
    "        data[\"Run\"].append(run + 1)  # Run number (1-10)\n",
    "        data[\"Modularity\"].append(results[algo][\"modularity\"][run])\n",
    "        data[\"Communities\"].append(results[algo][\"communities\"][run])\n",
    "        data[\"Time (s)\"].append(results[algo][\"time\"][run])\n",
    "\n",
    "# Creating the DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame for visual inspection\n",
    "print(results_df)\n",
    "\n",
    "# Additionally, creating a summary DataFrame for averages\n",
    "summary_data = {\n",
    "    \"Algorithm\": [\"Louvain\", \"Leiden\"],\n",
    "    \"Avg. Modularity\": [results[\"Louvain\"][\"avg_modularity\"], results[\"Leiden\"][\"avg_modularity\"]],\n",
    "    \"Avg. Communities\": [results[\"Louvain\"][\"avg_communities\"], results[\"Leiden\"][\"avg_communities\"]],\n",
    "    \"Avg. Time (s)\": [results[\"Louvain\"][\"avg_time\"], results[\"Leiden\"][\"avg_time\"]]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'JUST_CD_Experiment_Values.csv'\n",
    "results_df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
