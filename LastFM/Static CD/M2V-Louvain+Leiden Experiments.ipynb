{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Analysis of Static Community Detection Using M2V\n",
    "\n",
    "Running both the Louvain and Leiden algorithms multiple times and recording various statistics for each run can provide valuable insights for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Edge List w/ Weights to NetworkX\n",
    "\n",
    "NetworkX's read_weighted_edgelist function expects a simple text file with lines of the form <node1> <node2> <weight>, without headers. Since our data is in CSV format, you'll need to use Pandas (or another method) to load the CSV and adjust it to become readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source  target    weight\n",
      "0          u_2    a_51  0.382745\n",
      "1          u_2    a_52  0.310352\n",
      "2          u_2    a_53  0.336436\n",
      "3          u_2    a_54  0.299376\n",
      "4          u_2    a_55  0.266599\n",
      "...        ...     ...       ...\n",
      "160877  u_2099  u_1801  0.621778\n",
      "160878  u_2099  u_2006  0.625820\n",
      "160879  u_2099  u_2016  0.535882\n",
      "160880  u_2100   u_586  0.815714\n",
      "160881  u_2100   u_607  0.785083\n",
      "\n",
      "[160882 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edge_list_df = pd.read_csv('New Input/M2V_edge_list_with_similarity.csv')\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges with negative weights: 11\n"
     ]
    }
   ],
   "source": [
    "negative_weights = edge_list_df[edge_list_df['weight'] < 0]\n",
    "print(f\"Number of edges with negative weights: {len(negative_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Louvain is not made to consider negative edge weights, we will rescale the weights such that instead of [-1, 1] being the range, it is now [0, 1], where 0 now represents perfect dissimilarity, 0.5 represents orthogonality, and 1 represents perfect similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source  target    weight\n",
      "0          u_2    a_51  0.691372\n",
      "1          u_2    a_52  0.655176\n",
      "2          u_2    a_53  0.668218\n",
      "3          u_2    a_54  0.649688\n",
      "4          u_2    a_55  0.633300\n",
      "...        ...     ...       ...\n",
      "160877  u_2099  u_1801  0.810889\n",
      "160878  u_2099  u_2006  0.812910\n",
      "160879  u_2099  u_2016  0.767941\n",
      "160880  u_2100   u_586  0.907857\n",
      "160881  u_2100   u_607  0.892541\n",
      "\n",
      "[160882 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "edge_list_df['weight'] = (edge_list_df['weight'] + 1) / 2\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the creation of a graph, NetworkX specifies that an undirected, weighted graph must not have self-loop, parallel edges (A->B, B->A), or duplicate edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate edges: 0\n",
      "Number of self-loops: 0\n",
      "source    0\n",
      "target    0\n",
      "weight    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "print(f\"Number of duplicate edges: {duplicate_edges.sum()}\")\n",
    "\n",
    "self_loops = edge_list_df[edge_list_df['source'] == edge_list_df['target']]\n",
    "print(f\"Number of self-loops: {len(self_loops)}\")\n",
    "\n",
    "print(edge_list_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [source, target, weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate edges (ignoring the weight column)\n",
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "\n",
    "# Filter to get only the duplicate edges\n",
    "parallel_edges_df = edge_list_df[duplicate_edges]\n",
    "\n",
    "# Sort to better visualize parallel edges\n",
    "parallel_edges_sorted = parallel_edges_df.sort_values(by=['source', 'target'])\n",
    "\n",
    "print(parallel_edges_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Undirected Weighted Graph\n",
    "\n",
    "We iterate over the edge list DataFrame rows to add edges along with their weights to a new NetworkX graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_graph_info(graph):\n",
    "    print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"Number of edges:\", graph.number_of_edges())\n",
    "    \n",
    "    # Checking the graph type to provide appropriate information\n",
    "    if isinstance(graph, nx.DiGraph):\n",
    "        print(\"Graph is Directed\")\n",
    "    else:\n",
    "        print(\"Graph is Undirected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new graph\n",
    "G = nx.MultiGraph()\n",
    "\n",
    "# Add edges and weights\n",
    "for index, row in edge_list_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    weight = row['weight']\n",
    "    \n",
    "    # Add the edge with weight\n",
    "    G.add_edge(source, target, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 21518\n",
      "Number of edges: 160882\n",
      "Graph is Undirected\n"
     ]
    }
   ],
   "source": [
    "get_graph_info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Louvain Using CDLIB\n",
    "\n",
    "CDlib (Community Discovery Library) is designed for community detection and analysis, providing easy access to various algorithms, including Louvain and Leiden, and tools for evaluating and visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'bayanpy', 'wurlitzer', 'infomap', 'graph_tool'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'pyclustering', 'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'infomap'}\n"
     ]
    }
   ],
   "source": [
    "from cdlib import algorithms\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data structure for results\n",
    "results = {\n",
    "    \"Louvain\": {\"modularity\": [], \"communities\": [], \"time\": []},\n",
    "    \"Leiden\": {\"modularity\": [], \"communities\": [], \"time\": []}\n",
    "}\n",
    "\n",
    "# Execute each algorithm 10 times\n",
    "for _ in range(10):\n",
    "    # Louvain\n",
    "    start_time = time.time()\n",
    "    communities_louvain = algorithms.louvain(G, weight='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Louvain\"][\"modularity\"].append(communities_louvain.newman_girvan_modularity().score)\n",
    "    results[\"Louvain\"][\"communities\"].append(len(communities_louvain.communities))\n",
    "    results[\"Louvain\"][\"time\"].append(elapsed_time)\n",
    "    \n",
    "    # Leiden\n",
    "    start_time = time.time()\n",
    "    communities_leiden = algorithms.leiden(G, weights='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Leiden\"][\"modularity\"].append(communities_leiden.newman_girvan_modularity().score)\n",
    "    results[\"Leiden\"][\"communities\"].append(len(communities_leiden.communities))\n",
    "    results[\"Leiden\"][\"time\"].append(elapsed_time)\n",
    "\n",
    "# Calculate averages\n",
    "for method in results:\n",
    "    results[method][\"avg_modularity\"] = np.mean(results[method][\"modularity\"])\n",
    "    results[method][\"avg_time\"] = np.mean(results[method][\"time\"])\n",
    "    results[method][\"avg_communities\"] = np.mean(results[method][\"communities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Louvain': {'modularity': [0.6283189622703926, 0.6239206887763508, 0.6207736401838099, 0.6047938075823897, 0.6194606737894817, 0.6263972528573543, 0.6270822986517753, 0.6090804819676654, 0.607820917594113, 0.6281472523656049], 'communities': [526, 524, 569, 602, 530, 559, 504, 576, 611, 533], 'time': [9.93134593963623, 10.062281847000122, 8.868818998336792, 11.677879095077515, 10.732498168945312, 16.685330152511597, 9.61427092552185, 13.594332933425903, 10.162024974822998, 15.877521753311157], 'avg_modularity': 0.6195795976038938, 'avg_time': 11.720630478858947, 'avg_communities': 553.4}, 'Leiden': {'modularity': [0.6483667425717156, 0.6563998740574589, 0.6550958452567309, 0.6576852550101386, 0.6537452446750377, 0.6546388222351064, 0.6508864564381631, 0.6553832415913885, 0.6560937728574486, 0.6564500895912573], 'communities': [15, 18, 16, 17, 15, 16, 17, 16, 19, 14], 'time': [3.166872024536133, 3.2366371154785156, 3.099907159805298, 2.9914469718933105, 3.037999153137207, 3.026902198791504, 3.1300580501556396, 3.038904905319214, 3.196068048477173, 2.931077003479004], 'avg_modularity': 0.6544745344284445, 'avg_time': 3.0855872631073, 'avg_communities': 16.3}}\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Algorithm  Run  Modularity  Communities   Time (s)\n",
      "0    Louvain    1    0.628319          526   9.931346\n",
      "1    Louvain    2    0.623921          524  10.062282\n",
      "2    Louvain    3    0.620774          569   8.868819\n",
      "3    Louvain    4    0.604794          602  11.677879\n",
      "4    Louvain    5    0.619461          530  10.732498\n",
      "5    Louvain    6    0.626397          559  16.685330\n",
      "6    Louvain    7    0.627082          504   9.614271\n",
      "7    Louvain    8    0.609080          576  13.594333\n",
      "8    Louvain    9    0.607821          611  10.162025\n",
      "9    Louvain   10    0.628147          533  15.877522\n",
      "10    Leiden    1    0.648367           15   3.166872\n",
      "11    Leiden    2    0.656400           18   3.236637\n",
      "12    Leiden    3    0.655096           16   3.099907\n",
      "13    Leiden    4    0.657685           17   2.991447\n",
      "14    Leiden    5    0.653745           15   3.037999\n",
      "15    Leiden    6    0.654639           16   3.026902\n",
      "16    Leiden    7    0.650886           17   3.130058\n",
      "17    Leiden    8    0.655383           16   3.038905\n",
      "18    Leiden    9    0.656094           19   3.196068\n",
      "19    Leiden   10    0.656450           14   2.931077\n",
      "  Algorithm  Avg. Modularity  Avg. Communities  Avg. Time (s)\n",
      "0   Louvain         0.619580             553.4      11.720630\n",
      "1    Leiden         0.654475              16.3       3.085587\n"
     ]
    }
   ],
   "source": [
    "# Convert the results dictionary into a pandas DataFrame\n",
    "# First, prepare the data in a structured form\n",
    "data = {\n",
    "    \"Algorithm\": [],\n",
    "    \"Run\": [],\n",
    "    \"Modularity\": [],\n",
    "    \"Communities\": [],\n",
    "    \"Time (s)\": []\n",
    "}\n",
    "\n",
    "# Populate the structured data from the results\n",
    "for algo in results:\n",
    "    for run in range(10):  # Assuming 10 runs as previously set\n",
    "        data[\"Algorithm\"].append(algo)\n",
    "        data[\"Run\"].append(run + 1)  # Run number (1-10)\n",
    "        data[\"Modularity\"].append(results[algo][\"modularity\"][run])\n",
    "        data[\"Communities\"].append(results[algo][\"communities\"][run])\n",
    "        data[\"Time (s)\"].append(results[algo][\"time\"][run])\n",
    "\n",
    "# Creating the DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame for visual inspection\n",
    "print(results_df)\n",
    "\n",
    "# Additionally, creating a summary DataFrame for averages\n",
    "summary_data = {\n",
    "    \"Algorithm\": [\"Louvain\", \"Leiden\"],\n",
    "    \"Avg. Modularity\": [results[\"Louvain\"][\"avg_modularity\"], results[\"Leiden\"][\"avg_modularity\"]],\n",
    "    \"Avg. Communities\": [results[\"Louvain\"][\"avg_communities\"], results[\"Leiden\"][\"avg_communities\"]],\n",
    "    \"Avg. Time (s)\": [results[\"Louvain\"][\"avg_time\"], results[\"Leiden\"][\"avg_time\"]]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'M2V_CD_Experiment_Values.csv'\n",
    "results_df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
