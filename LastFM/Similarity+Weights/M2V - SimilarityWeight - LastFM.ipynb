{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Similarity & Weight Projection - M2V\n",
    "\n",
    "After extracting the learned node embeddings from the LastFM database using Metapath2Vec, we will input and process the respective CSV and txt files to calculate `Cosine Similarity` between any two nodes sharing an edge in the original graph.\n",
    "\n",
    "We first import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Embeddings Data from CSV\n",
    "\n",
    "Since your embeddings are saved in a CSV file, we will use Pandas to load this file into a DataFrame. Each row in CSV file represents a node, and each column represents a feature of the embeddings (i.e., 128-dimension embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6    \\\n",
      "node_id                                                                         \n",
      "t_73    -0.193153  0.081209  0.221022 -0.237067 -0.341212 -0.124392  0.518349   \n",
      "t_24    -0.378580  0.373095  0.419321 -0.144066 -0.177232 -0.074142  0.437567   \n",
      "t_79    -0.360389  0.083494  0.088490 -0.351976 -0.175297 -0.167279  0.257180   \n",
      "t_18    -0.356609  0.005678  0.402312 -0.554622 -0.022824  0.020642 -0.036826   \n",
      "t_81    -0.248152 -0.063090  0.202308 -0.197242 -0.130315 -0.201546  0.333233   \n",
      "\n",
      "              7         8         9    ...       118       119       120  \\\n",
      "node_id                                ...                                 \n",
      "t_73     0.239695 -0.272634 -0.135897  ...  0.174696  0.110674  0.100949   \n",
      "t_24     0.540218 -0.267260  0.076700  ...  0.452497  0.030775  0.230328   \n",
      "t_79     0.460405 -0.298290 -0.080821  ...  0.350925  0.013836  0.011780   \n",
      "t_18     0.425137 -0.540539 -0.208693  ...  0.457652  0.355199 -0.175280   \n",
      "t_81     0.321245 -0.580546  0.083575  ...  0.029460  0.599169  0.125027   \n",
      "\n",
      "              121       122       123       124       125       126       127  \n",
      "node_id                                                                        \n",
      "t_73     0.033665  0.075441  0.331266  0.020202 -0.213357 -0.107091  0.157276  \n",
      "t_24    -0.338027  0.048291  0.491815  0.106747 -0.172917 -0.281297  0.118938  \n",
      "t_79    -0.139148 -0.189243  0.288592 -0.111147  0.163391 -0.107350  0.362807  \n",
      "t_18    -0.539665 -0.307221  0.262405  0.137945 -0.038897 -0.614187  0.010464  \n",
      "t_81    -0.064965 -0.415897  0.071050 -0.046679  0.193068 -0.339528  0.056438  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21518, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df = pd.read_csv('M2V_Embeddings/node_embeddings.csv', delimiter=',', header=None, float_precision='high')\n",
    "\n",
    "with open('M2V_Embeddings/node_ids.txt', 'r') as file:\n",
    "    node_indexes = [line.strip() for line in file]\n",
    "\n",
    "# Add node_indexes back as the first column of the DataFrame\n",
    "embeddings_df.insert(0, 'node_id', node_indexes)\n",
    "\n",
    "# Set node indexes as embeddings_df index to allow for faster search later on\n",
    "embeddings_df.set_index('node_id', inplace=True)\n",
    "\n",
    "# Now 'embeddings_df' is ready for further analysis\n",
    "print(embeddings_df.head())\n",
    "\n",
    "embeddings_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned-up the embeddings into a dataframe, we need to check if there are any inconsistencies in the data. We also check for non-numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      " 0      float64\n",
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "        ...   \n",
      "123    float64\n",
      "124    float64\n",
      "125    float64\n",
      "126    float64\n",
      "127    float64\n",
      "Length: 128, dtype: object\n",
      "DataFrame shape: (21518, 128)\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric data\n",
    "print(\"Data types:\\n\", embeddings_df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "if embeddings_df.isnull().values.any():\n",
    "    print(\"Missing values found\")\n",
    "\n",
    "# Check shape of embeddings dataframe to see if there are varying row lengths\n",
    "print(\"DataFrame shape:\", embeddings_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Edge List Data from .edgelist File\n",
    "\n",
    "To be able to access which nodes are connected by an edge, we need to import the edge list into another dataframe. Note that the node IDs must be consistent across both the embedding and edge list dataframes! It is also an undirected graph, meaning source and target do not necessarily mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source target\n",
       "0    u_2   a_51\n",
       "1    u_2   a_52\n",
       "2    u_2   a_53\n",
       "3    u_2   a_54\n",
       "4    u_2   a_55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_73</th>\n",
       "      <td>-0.193153</td>\n",
       "      <td>0.081209</td>\n",
       "      <td>0.221022</td>\n",
       "      <td>-0.237067</td>\n",
       "      <td>-0.341212</td>\n",
       "      <td>-0.124392</td>\n",
       "      <td>0.518349</td>\n",
       "      <td>0.239695</td>\n",
       "      <td>-0.272634</td>\n",
       "      <td>-0.135897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174696</td>\n",
       "      <td>0.110674</td>\n",
       "      <td>0.100949</td>\n",
       "      <td>0.033665</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.331266</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>-0.213357</td>\n",
       "      <td>-0.107091</td>\n",
       "      <td>0.157276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_24</th>\n",
       "      <td>-0.378580</td>\n",
       "      <td>0.373095</td>\n",
       "      <td>0.419321</td>\n",
       "      <td>-0.144066</td>\n",
       "      <td>-0.177232</td>\n",
       "      <td>-0.074142</td>\n",
       "      <td>0.437567</td>\n",
       "      <td>0.540218</td>\n",
       "      <td>-0.267260</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452497</td>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.230328</td>\n",
       "      <td>-0.338027</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>0.491815</td>\n",
       "      <td>0.106747</td>\n",
       "      <td>-0.172917</td>\n",
       "      <td>-0.281297</td>\n",
       "      <td>0.118938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_79</th>\n",
       "      <td>-0.360389</td>\n",
       "      <td>0.083494</td>\n",
       "      <td>0.088490</td>\n",
       "      <td>-0.351976</td>\n",
       "      <td>-0.175297</td>\n",
       "      <td>-0.167279</td>\n",
       "      <td>0.257180</td>\n",
       "      <td>0.460405</td>\n",
       "      <td>-0.298290</td>\n",
       "      <td>-0.080821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350925</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>-0.139148</td>\n",
       "      <td>-0.189243</td>\n",
       "      <td>0.288592</td>\n",
       "      <td>-0.111147</td>\n",
       "      <td>0.163391</td>\n",
       "      <td>-0.107350</td>\n",
       "      <td>0.362807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_18</th>\n",
       "      <td>-0.356609</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.402312</td>\n",
       "      <td>-0.554622</td>\n",
       "      <td>-0.022824</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>0.425137</td>\n",
       "      <td>-0.540539</td>\n",
       "      <td>-0.208693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457652</td>\n",
       "      <td>0.355199</td>\n",
       "      <td>-0.175280</td>\n",
       "      <td>-0.539665</td>\n",
       "      <td>-0.307221</td>\n",
       "      <td>0.262405</td>\n",
       "      <td>0.137945</td>\n",
       "      <td>-0.038897</td>\n",
       "      <td>-0.614187</td>\n",
       "      <td>0.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_81</th>\n",
       "      <td>-0.248152</td>\n",
       "      <td>-0.063090</td>\n",
       "      <td>0.202308</td>\n",
       "      <td>-0.197242</td>\n",
       "      <td>-0.130315</td>\n",
       "      <td>-0.201546</td>\n",
       "      <td>0.333233</td>\n",
       "      <td>0.321245</td>\n",
       "      <td>-0.580546</td>\n",
       "      <td>0.083575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029460</td>\n",
       "      <td>0.599169</td>\n",
       "      <td>0.125027</td>\n",
       "      <td>-0.064965</td>\n",
       "      <td>-0.415897</td>\n",
       "      <td>0.071050</td>\n",
       "      <td>-0.046679</td>\n",
       "      <td>0.193068</td>\n",
       "      <td>-0.339528</td>\n",
       "      <td>0.056438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "node_id                                                                         \n",
       "t_73    -0.193153  0.081209  0.221022 -0.237067 -0.341212 -0.124392  0.518349   \n",
       "t_24    -0.378580  0.373095  0.419321 -0.144066 -0.177232 -0.074142  0.437567   \n",
       "t_79    -0.360389  0.083494  0.088490 -0.351976 -0.175297 -0.167279  0.257180   \n",
       "t_18    -0.356609  0.005678  0.402312 -0.554622 -0.022824  0.020642 -0.036826   \n",
       "t_81    -0.248152 -0.063090  0.202308 -0.197242 -0.130315 -0.201546  0.333233   \n",
       "\n",
       "              7         8         9    ...       118       119       120  \\\n",
       "node_id                                ...                                 \n",
       "t_73     0.239695 -0.272634 -0.135897  ...  0.174696  0.110674  0.100949   \n",
       "t_24     0.540218 -0.267260  0.076700  ...  0.452497  0.030775  0.230328   \n",
       "t_79     0.460405 -0.298290 -0.080821  ...  0.350925  0.013836  0.011780   \n",
       "t_18     0.425137 -0.540539 -0.208693  ...  0.457652  0.355199 -0.175280   \n",
       "t_81     0.321245 -0.580546  0.083575  ...  0.029460  0.599169  0.125027   \n",
       "\n",
       "              121       122       123       124       125       126       127  \n",
       "node_id                                                                        \n",
       "t_73     0.033665  0.075441  0.331266  0.020202 -0.213357 -0.107091  0.157276  \n",
       "t_24    -0.338027  0.048291  0.491815  0.106747 -0.172917 -0.281297  0.118938  \n",
       "t_79    -0.139148 -0.189243  0.288592 -0.111147  0.163391 -0.107350  0.362807  \n",
       "t_18    -0.539665 -0.307221  0.262405  0.137945 -0.038897 -0.614187  0.010464  \n",
       "t_81    -0.064965 -0.415897  0.071050 -0.046679  0.193068 -0.339528  0.056438  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File path\n",
    "edgelist_file = 'EdgeList_LastFM/lastfm.edgelist'\n",
    "\n",
    "# Read edge list into DataFrame\n",
    "edge_list_df = pd.read_csv(edgelist_file, sep=' ', header=None, names=['source', 'target'])\n",
    "\n",
    "display(edge_list_df.head())\n",
    "\n",
    "display(embeddings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Cosine Similarity\n",
    "\n",
    "- For each edge, we retrieve the embeddings of the connected nodes.\n",
    "- Use cosine_similarity from sklearn.metrics.pairwise to calculate the similarity for each edge.\n",
    "- Store the similarity values in a new column in the edge list DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Row-by-Row Iteration (Slower, Inefficient)\n",
    "\n",
    "For graphs with a very large number of edges, iterating over each row using DataFrame.iterrows() and calculating cosine similarity one pair at a time can be very inefficient. This method has a time complexity that grows linearly with the number of edges, leading to long execution times for large graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-159a1f015015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0memb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0memb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0;32m-> 1189\u001b[0;31m                         dense_output=dense_output)\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \"\"\"Dot product that handle the sparse matrix case correctly.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assume embeddings_df is your DataFrame with embeddings indexed by node IDs\n",
    "# Calculate cosine similarities\n",
    "similarities = []\n",
    "for _, row in edge_list_df.iterrows():\n",
    "    emb1 = embeddings_df.loc[row['source']].values.reshape(1, -1)\n",
    "    emb2 = embeddings_df.loc[row['target']].values.reshape(1, -1)\n",
    "    similarity = cosine_similarity(emb1, emb2)[0, 0]\n",
    "    similarities.append(similarity)\n",
    "\n",
    "# Add similarities to the edge list DataFrame\n",
    "edge_list_df['weight'] = similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Batch Processing using Vectorization (Faster, Efficient)\n",
    "\n",
    "1. Efficiency and Vectorization\n",
    "    - Vectorized Operations: Modern CPUs and computing frameworks like NumPy are optimized for vectorized operations, where the same operation is performed simultaneously on multiple data points. This is inherently more efficient than processing each data point (or in this case, each pair of embeddings) individually, as it minimizes the overhead associated with looping constructs in high-level languages like Python.\n",
    "\n",
    "    - Batch Processing: By processing multiple pairs of embeddings at once, the batch approach reduces the number of iterations and takes full advantage of vectorized operations. This leads to a significant reduction in computation time, especially for large datasets.\n",
    "\n",
    "2. Scalability\n",
    "    - Memory Management: Calculating cosine similarities for millions of edges at once can be memory-intensive, leading to memory overflow or significantly slowed performance due to swapping. Processing the data in smaller batches helps manage memory usage more effectively, ensuring that the computation remains within the available system resources, thereby maintaining performance across varying scales of data.\n",
    "\n",
    "    - Parallelization Potential: Although not implemented in the provided code, batch processing opens up possibilities for parallel computation. Batches can be processed in parallel across multiple CPU cores or even distributed systems, further speeding up the computation for very large graphs.\n",
    "\n",
    "3. Practicality\n",
    "    - Adaptability: The batch size can be adjusted based on the available computing resources and the specific requirements of the dataset. This flexibility allows the method to be optimized for different environments, from personal laptops to high-performance computing clusters.\n",
    "\n",
    "    - Reduced Computational Overhead: The original method's reliance on DataFrame.iterrows() is known to be inefficient for large datasets due to the overhead of generating Series objects for each row. In contrast, the batch processing approach minimizes this overhead by working directly with NumPy arrays, which are more efficient both in terms of memory layout and computational performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume embeddings_df is indexed by node IDs and contains embeddings\n",
    "embeddings = embeddings_df.to_numpy()\n",
    "\n",
    "# Map node IDs to their index in the embeddings array for quick lookup\n",
    "node_id_to_index = {node_id: index for index, node_id in enumerate(embeddings_df.index)}\n",
    "\n",
    "# Convert edge list source and target to indices\n",
    "edge_indices = [(node_id_to_index[row['source']], node_id_to_index[row['target']])\n",
    "                for _, row in edge_list_df.iterrows()]\n",
    "\n",
    "# Calculate similarities in batches to manage memory usage\n",
    "batch_size = 1000  # Adjust based on your memory capacity\n",
    "similarities = []\n",
    "\n",
    "for i in range(0, len(edge_indices), batch_size):\n",
    "    batch_edges = edge_indices[i:i+batch_size]\n",
    "    emb1 = np.array([embeddings[index_pair[0]] for index_pair in batch_edges])\n",
    "    emb2 = np.array([embeddings[index_pair[1]] for index_pair in batch_edges])\n",
    "    \n",
    "    # Calculate batch similarities\n",
    "    batch_similarities = cosine_similarity(emb1, emb2).diagonal()\n",
    "    similarities.extend(batch_similarities)\n",
    "\n",
    "# Add similarities to the edge list DataFrame\n",
    "edge_list_df['weight'] = similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_51</td>\n",
       "      <td>0.382745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_52</td>\n",
       "      <td>0.310352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_53</td>\n",
       "      <td>0.336436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_54</td>\n",
       "      <td>0.299376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_2</td>\n",
       "      <td>a_55</td>\n",
       "      <td>0.266599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>u_3</td>\n",
       "      <td>a_146</td>\n",
       "      <td>0.458373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>u_3</td>\n",
       "      <td>a_147</td>\n",
       "      <td>0.802212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>u_3</td>\n",
       "      <td>a_148</td>\n",
       "      <td>0.559444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>u_3</td>\n",
       "      <td>a_149</td>\n",
       "      <td>0.816774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>u_3</td>\n",
       "      <td>a_150</td>\n",
       "      <td>0.734517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source target    weight\n",
       "0     u_2   a_51  0.382745\n",
       "1     u_2   a_52  0.310352\n",
       "2     u_2   a_53  0.336436\n",
       "3     u_2   a_54  0.299376\n",
       "4     u_2   a_55  0.266599\n",
       "..    ...    ...       ...\n",
       "95    u_3  a_146  0.458373\n",
       "96    u_3  a_147  0.802212\n",
       "97    u_3  a_148  0.559444\n",
       "98    u_3  a_149  0.816774\n",
       "99    u_3  a_150  0.734517\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(edge_list_df.head(100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export the new updated edge list with cosine similarities as edge weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the updated edge list\n",
    "edge_list_df.to_csv('M2V_edge_list_with_similarity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
