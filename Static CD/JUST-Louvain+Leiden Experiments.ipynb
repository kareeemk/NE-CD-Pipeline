{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Analysis of Static Community Detection Using JUST\n",
    "\n",
    "Running both the Louvain and Leiden algorithms multiple times and recording various statistics for each run can provide valuable insights for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Edge List w/ Weights to NetworkX\n",
    "\n",
    "NetworkX's read_weighted_edgelist function expects a simple text file with lines of the form <node1> <node2> <weight>, without headers. Since our data is in CSV format, you'll need to use Pandas (or another method) to load the CSV and adjust it to become readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       source  target    weight\n",
      "0          p0      a1  0.810501\n",
      "1          p0      a2  0.825994\n",
      "2          p0      a3  0.846090\n",
      "3          p0      a4  0.766287\n",
      "4          p0      a5  0.839626\n",
      "...       ...     ...       ...\n",
      "51372  p10169   p8094  0.586715\n",
      "51373  p10169   p7974  0.669212\n",
      "51374  p10169   p5852  0.599799\n",
      "51375  p10169  p10113  0.639972\n",
      "51376  p10169  p10031  0.488926\n",
      "\n",
      "[51377 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edge_list_df = pd.read_csv('New Input/JUST_edge_list_with_similarity.csv')\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges with negative weights: 21\n"
     ]
    }
   ],
   "source": [
    "negative_weights = edge_list_df[edge_list_df['weight'] < 0]\n",
    "print(f\"Number of edges with negative weights: {len(negative_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Louvain is not made to consider negative edge weights, we will rescale the weights such that instead of [-1, 1] being the range, it is now [0, 1], where 0 now represents perfect dissimilarity, 0.5 represents orthogonality, and 1 represents perfect similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       source  target    weight\n",
      "0          p0      a1  0.905251\n",
      "1          p0      a2  0.912997\n",
      "2          p0      a3  0.923045\n",
      "3          p0      a4  0.883144\n",
      "4          p0      a5  0.919813\n",
      "...       ...     ...       ...\n",
      "51372  p10169   p8094  0.793358\n",
      "51373  p10169   p7974  0.834606\n",
      "51374  p10169   p5852  0.799899\n",
      "51375  p10169  p10113  0.819986\n",
      "51376  p10169  p10031  0.744463\n",
      "\n",
      "[51377 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "edge_list_df['weight'] = (edge_list_df['weight'] + 1) / 2\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the creation of a graph, NetworkX specifies that an undirected, weighted graph must not have self-loop, parallel edges (A->B, B->A), or duplicate edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate edges: 0\n",
      "Number of self-loops: 4\n",
      "      source target  weight\n",
      "2030    p661   p661     1.0\n",
      "18335  p4680  p4680     1.0\n",
      "25834  p6225  p6225     1.0\n",
      "45560  p9359  p9359     1.0\n",
      "source    0\n",
      "target    0\n",
      "weight    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "print(f\"Number of duplicate edges: {duplicate_edges.sum()}\")\n",
    "\n",
    "self_loops = edge_list_df[edge_list_df['source'] == edge_list_df['target']]\n",
    "print(f\"Number of self-loops: {len(self_loops)}\")\n",
    "print(self_loops)\n",
    "\n",
    "print(edge_list_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges before dropping self-loops: 51377\n",
      "Number of edges after dropping self-loops: 51373\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of edges before dropping self-loops: {len(edge_list_df)}\")\n",
    "\n",
    "edge_list_df = edge_list_df[edge_list_df['source'] != edge_list_df['target']]\n",
    "\n",
    "print(f\"Number of edges after dropping self-loops: {len(edge_list_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [source, target, weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate edges (ignoring the weight column)\n",
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "\n",
    "# Filter to get only the duplicate edges\n",
    "parallel_edges_df = edge_list_df[duplicate_edges]\n",
    "\n",
    "# Sort to better visualize parallel edges\n",
    "parallel_edges_sorted = parallel_edges_df.sort_values(by=['source', 'target'])\n",
    "\n",
    "print(parallel_edges_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Undirected Weighted Graph\n",
    "\n",
    "We iterate over the edge list DataFrame rows to add edges along with their weights to a new NetworkX graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_graph_info(graph):\n",
    "    print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"Number of edges:\", graph.number_of_edges())\n",
    "    \n",
    "    # Checking the graph type to provide appropriate information\n",
    "    if isinstance(graph, nx.DiGraph):\n",
    "        print(\"Graph is Directed\")\n",
    "    else:\n",
    "        print(\"Graph is Undirected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new graph\n",
    "G = nx.MultiGraph()\n",
    "\n",
    "# Add edges and weights\n",
    "for index, row in edge_list_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    weight = row['weight']\n",
    "    \n",
    "    # Add the edge with weight\n",
    "    G.add_edge(source, target, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 15649\n",
      "Number of edges: 51373\n",
      "Graph is Undirected\n"
     ]
    }
   ],
   "source": [
    "get_graph_info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Louvain Using CDLIB\n",
    "\n",
    "CDlib (Community Discovery Library) is designed for community detection and analysis, providing easy access to various algorithms, including Louvain and Leiden, and tools for evaluating and visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer', 'bayanpy', 'graph_tool'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw', 'pyclustering'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "from cdlib import algorithms\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data structure for results\n",
    "results = {\n",
    "    \"Louvain\": {\"modularity\": [], \"communities\": [], \"time\": []},\n",
    "    \"Leiden\": {\"modularity\": [], \"communities\": [], \"time\": []}\n",
    "}\n",
    "\n",
    "# Execute each algorithm 10 times\n",
    "for _ in range(10):\n",
    "    # Louvain\n",
    "    start_time = time.time()\n",
    "    communities_louvain = algorithms.louvain(G, weight='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Louvain\"][\"modularity\"].append(communities_louvain.newman_girvan_modularity().score)\n",
    "    results[\"Louvain\"][\"communities\"].append(len(communities_louvain.communities))\n",
    "    results[\"Louvain\"][\"time\"].append(elapsed_time)\n",
    "    \n",
    "    # Leiden\n",
    "    start_time = time.time()\n",
    "    communities_leiden = algorithms.leiden(G, weights='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Leiden\"][\"modularity\"].append(communities_leiden.newman_girvan_modularity().score)\n",
    "    results[\"Leiden\"][\"communities\"].append(len(communities_leiden.communities))\n",
    "    results[\"Leiden\"][\"time\"].append(elapsed_time)\n",
    "\n",
    "# Calculate averages\n",
    "for method in results:\n",
    "    results[method][\"avg_modularity\"] = np.mean(results[method][\"modularity\"])\n",
    "    results[method][\"avg_time\"] = np.mean(results[method][\"time\"])\n",
    "    results[method][\"avg_communities\"] = np.mean(results[method][\"communities\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Louvain': {'modularity': [0.5957159635089166, 0.5805000889617737, 0.6463605882871974, 0.588060428829819, 0.616711752889861, 0.6010318802797675, 0.5968676812202742, 0.5854100176117693, 0.6035033660424804, 0.6224959471735716], 'communities': [1820, 1898, 1581, 1819, 1689, 1785, 1831, 1867, 1739, 1663], 'time': [11.768126964569092, 10.624771118164062, 5.055445909500122, 5.814736843109131, 5.640079975128174, 5.766633987426758, 7.036201238632202, 9.15189504623413, 6.269519090652466, 8.56113314628601], 'avg_modularity': 0.6036657714805431, 'avg_time': 7.568854331970215, 'avg_communities': 1769.2}, 'Leiden': {'modularity': [0.7428975802369394, 0.7310618570501866, 0.734277640290517, 0.7413171119681695, 0.7365376343645264, 0.7350904352275499, 0.7369605110560752, 0.737211348320968, 0.7390722449437401, 0.7400887605465057], 'communities': [29, 29, 27, 31, 26, 28, 28, 27, 26, 26], 'time': [1.3771846294403076, 1.2270317077636719, 1.4036669731140137, 1.3829102516174316, 1.4404339790344238, 1.2599167823791504, 1.4031410217285156, 1.2784309387207031, 1.3841278553009033, 1.4120748043060303], 'avg_modularity': 0.7374515124005179, 'avg_time': 1.356891894340515, 'avg_communities': 27.7}}\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Algorithm  Run  Modularity  Communities   Time (s)\n",
      "0    Louvain    1    0.595716         1820  11.768127\n",
      "1    Louvain    2    0.580500         1898  10.624771\n",
      "2    Louvain    3    0.646361         1581   5.055446\n",
      "3    Louvain    4    0.588060         1819   5.814737\n",
      "4    Louvain    5    0.616712         1689   5.640080\n",
      "5    Louvain    6    0.601032         1785   5.766634\n",
      "6    Louvain    7    0.596868         1831   7.036201\n",
      "7    Louvain    8    0.585410         1867   9.151895\n",
      "8    Louvain    9    0.603503         1739   6.269519\n",
      "9    Louvain   10    0.622496         1663   8.561133\n",
      "10    Leiden    1    0.742898           29   1.377185\n",
      "11    Leiden    2    0.731062           29   1.227032\n",
      "12    Leiden    3    0.734278           27   1.403667\n",
      "13    Leiden    4    0.741317           31   1.382910\n",
      "14    Leiden    5    0.736538           26   1.440434\n",
      "15    Leiden    6    0.735090           28   1.259917\n",
      "16    Leiden    7    0.736961           28   1.403141\n",
      "17    Leiden    8    0.737211           27   1.278431\n",
      "18    Leiden    9    0.739072           26   1.384128\n",
      "19    Leiden   10    0.740089           26   1.412075\n",
      "  Algorithm  Avg. Modularity  Avg. Communities  Avg. Time (s)\n",
      "0   Louvain         0.603666            1769.2       7.568854\n",
      "1    Leiden         0.737452              27.7       1.356892\n"
     ]
    }
   ],
   "source": [
    "# Convert the results dictionary into a pandas DataFrame\n",
    "# First, prepare the data in a structured form\n",
    "data = {\n",
    "    \"Algorithm\": [],\n",
    "    \"Run\": [],\n",
    "    \"Modularity\": [],\n",
    "    \"Communities\": [],\n",
    "    \"Time (s)\": []\n",
    "}\n",
    "\n",
    "# Populate the structured data from the results\n",
    "for algo in results:\n",
    "    for run in range(10):  # Assuming 10 runs as previously set\n",
    "        data[\"Algorithm\"].append(algo)\n",
    "        data[\"Run\"].append(run + 1)  # Run number (1-10)\n",
    "        data[\"Modularity\"].append(results[algo][\"modularity\"][run])\n",
    "        data[\"Communities\"].append(results[algo][\"communities\"][run])\n",
    "        data[\"Time (s)\"].append(results[algo][\"time\"][run])\n",
    "\n",
    "# Creating the DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame for visual inspection\n",
    "print(results_df)\n",
    "\n",
    "# Additionally, creating a summary DataFrame for averages\n",
    "summary_data = {\n",
    "    \"Algorithm\": [\"Louvain\", \"Leiden\"],\n",
    "    \"Avg. Modularity\": [results[\"Louvain\"][\"avg_modularity\"], results[\"Leiden\"][\"avg_modularity\"]],\n",
    "    \"Avg. Communities\": [results[\"Louvain\"][\"avg_communities\"], results[\"Leiden\"][\"avg_communities\"]],\n",
    "    \"Avg. Time (s)\": [results[\"Louvain\"][\"avg_time\"], results[\"Leiden\"][\"avg_time\"]]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'JUST_CD_Experiment_Values.csv'\n",
    "results_df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
