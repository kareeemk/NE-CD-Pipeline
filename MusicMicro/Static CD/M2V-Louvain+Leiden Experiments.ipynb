{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Analysis of Static Community Detection Using M2V\n",
    "\n",
    "Running both the Louvain and Leiden algorithms multiple times and recording various statistics for each run can provide valuable insights for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Edge List w/ Weights to NetworkX\n",
    "\n",
    "NetworkX's read_weighted_edgelist function expects a simple text file with lines of the form <node1> <node2> <weight>, without headers. Since our data is in CSV format, you'll need to use Pandas (or another method) to load the CSV and adjust it to become readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            source    target    weight\n",
      "0        u74717431  t7748381  0.892881\n",
      "1       u127821914  t3529910  0.717761\n",
      "2       u174194590  t5762915  0.483259\n",
      "3       u141847381  t6987845  0.720264\n",
      "4        u87215499  t4082536  0.754541\n",
      "...            ...       ...       ...\n",
      "641138     ci20717       co3  0.772626\n",
      "641139     ci20718       co9  0.878173\n",
      "641140     ci20719       co5  0.737660\n",
      "641141     ci20720       co3  0.751880\n",
      "641142     ci20721       co4  0.766678\n",
      "\n",
      "[641143 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edge_list_df = pd.read_csv('Input/M2V_edge_list_with_similarity.csv')\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges with negative weights: 0\n"
     ]
    }
   ],
   "source": [
    "negative_weights = edge_list_df[edge_list_df['weight'] < 0]\n",
    "print(f\"Number of edges with negative weights: {len(negative_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Louvain is not made to consider negative edge weights, we will rescale the weights such that instead of [-1, 1] being the range, it is now [0, 1], where 0 now represents perfect dissimilarity, 0.5 represents orthogonality, and 1 represents perfect similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            source    target    weight\n",
      "0        u74717431  t7748381  0.946440\n",
      "1       u127821914  t3529910  0.858880\n",
      "2       u174194590  t5762915  0.741629\n",
      "3       u141847381  t6987845  0.860132\n",
      "4        u87215499  t4082536  0.877271\n",
      "...            ...       ...       ...\n",
      "641138     ci20717       co3  0.886313\n",
      "641139     ci20718       co9  0.939086\n",
      "641140     ci20719       co5  0.868830\n",
      "641141     ci20720       co3  0.875940\n",
      "641142     ci20721       co4  0.883339\n",
      "\n",
      "[641143 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "edge_list_df['weight'] = (edge_list_df['weight'] + 1) / 2\n",
    "\n",
    "print(edge_list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the creation of a graph, NetworkX specifies that an undirected, weighted graph must not have self-loop, parallel edges (A->B, B->A), or duplicate edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate edges: 0\n",
      "Number of self-loops: 0\n",
      "source    0\n",
      "target    0\n",
      "weight    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "print(f\"Number of duplicate edges: {duplicate_edges.sum()}\")\n",
    "\n",
    "self_loops = edge_list_df[edge_list_df['source'] == edge_list_df['target']]\n",
    "print(f\"Number of self-loops: {len(self_loops)}\")\n",
    "\n",
    "print(edge_list_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [source, target, weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate edges (ignoring the weight column)\n",
    "duplicate_edges = edge_list_df.duplicated(subset=['source', 'target'], keep=False)\n",
    "\n",
    "# Filter to get only the duplicate edges\n",
    "parallel_edges_df = edge_list_df[duplicate_edges]\n",
    "\n",
    "# Sort to better visualize parallel edges\n",
    "parallel_edges_sorted = parallel_edges_df.sort_values(by=['source', 'target'])\n",
    "\n",
    "print(parallel_edges_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for any non-numeric values in the weight column, since this will not be valid when input into a graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [source, target, weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for any non-numeric values in the 'weight' column\n",
    "non_numeric_weights = edge_list_df[pd.to_numeric(edge_list_df['weight'], errors='coerce').isna()]\n",
    "\n",
    "# Display rows with non-numeric or NaN weights\n",
    "print(non_numeric_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source     object\n",
      "target     object\n",
      "weight    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'weight' column to floating point values\n",
    "edge_list_df['weight'] = edge_list_df['weight'].astype(float)\n",
    "\n",
    "# Check the data type of the column to confirm the conversion\n",
    "print(edge_list_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Undirected Weighted NX Graph for Louvain\n",
    "\n",
    "We iterate over the edge list DataFrame rows to add edges along with their weights to a new NetworkX graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_graph_info(graph):\n",
    "    print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"Number of edges:\", graph.number_of_edges())\n",
    "    \n",
    "    # Checking the graph type to provide appropriate information\n",
    "    if isinstance(graph, nx.DiGraph):\n",
    "        print(\"Graph is Directed\")\n",
    "    else:\n",
    "        print(\"Graph is Undirected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new graph\n",
    "G = nx.MultiGraph()\n",
    "\n",
    "# Add edges and weights\n",
    "for index, row in edge_list_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    weight = row['weight']\n",
    "    \n",
    "    # Add the edge with weight\n",
    "    G.add_edge(source, target, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 245621\n",
      "Number of edges: 641143\n",
      "Graph is Undirected\n"
     ]
    }
   ],
   "source": [
    "get_graph_info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Undirected Weighted iGraph for Leiden\n",
    "\n",
    "Provided that running Leiden on the MusicMicro dataset was problematic, we decided to isolate the issue and directly use iGraph, as suggested by Leiden's authors.  \n",
    "\n",
    "We iterate over the edge list DataFrame rows to add edges into a tuple list, along with their weights in a separate list for input into a new iGraph graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9464404929422645, 0.8588802696312696, 0.7416292808281564, 0.8601320326015599, 0.8772707346584033]\n",
      "IGRAPH UNW- 245621 641143 -- \n",
      "+ attr: name (v), weight (e)\n"
     ]
    }
   ],
   "source": [
    "import igraph as ig\n",
    "\n",
    "# Assuming edge_list_df is your DataFrame\n",
    "edges_with_weights = [(row['source'], row['target'], row['weight']) for index, row in edge_list_df.iterrows()]\n",
    "\n",
    "# Creating the igraph Graph\n",
    "g = ig.Graph.TupleList(edges_with_weights, edge_attrs={'weight': [w for _, _, w in edges_with_weights]})\n",
    "\n",
    "# Now, check again if the weights have been correctly assigned\n",
    "print(g.es['weight'][:5])\n",
    "print(g.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Modularity, Run Time and No. of Communities\n",
    "\n",
    "- Iterates 10 times, running both the Louvain (using CDLib) and Leiden (using iGraph) algorithms on each iteration.\n",
    "- Records modularity, number of communities, and execution time for each run.\n",
    "- Calculates the average modularity, average number of communities, and average execution time for both algorithms across all runs.\n",
    "- Stores all this information in the results dictionary for easy access and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'wurlitzer', 'infomap', 'bayanpy'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw', 'pyclustering'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'infomap'}\n",
      "{'Louvain': {'modularity': [0.7107906293333608, 0.7146033550336707, 0.7100781811219058, 0.711286922818838, 0.7104126879038287, 0.7107213783426581, 0.7112670943582213, 0.7140453817597964, 0.7109466649870047, 0.7102647930672743], 'communities': [270, 407, 323, 317, 276, 314, 346, 131, 271, 378], 'time': [140.05474710464478, 185.6614499092102, 155.41062927246094, 143.72338771820068, 165.8080689907074, 114.40305089950562, 145.0077781677246, 146.19717693328857, 183.72993516921997, 167.2318778038025], 'avg_modularity': 0.7114417088726559, 'avg_time': 154.72281019687654, 'avg_communities': 303.3}, 'Leiden': {'modularity': [0.6061964131056568, 0.6077849209284348, 0.6039175958946954, 0.6085297553859685, 0.6031347141821898, 0.6097619507061808, 0.6060376328682938, 0.6013012777554784, 0.6025305536021106, 0.6052087022958809], 'communities': [314, 291, 282, 219, 382, 246, 307, 287, 348, 254], 'time': [15.384473085403442, 16.508063793182373, 15.92988896369934, 17.097694158554077, 16.93193292617798, 17.44502305984497, 15.634144067764282, 16.402777194976807, 16.290759801864624, 16.788152933120728], 'avg_modularity': 0.605440351672489, 'avg_time': 16.44129099845886, 'avg_communities': 293.0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from cdlib import algorithms\n",
    "import leidenalg\n",
    "\n",
    "# Prepare lists to store results\n",
    "results = {\n",
    "    \"Louvain\": {\"modularity\": [], \"communities\": [], \"time\": []},\n",
    "    \"Leiden\": {\"modularity\": [], \"communities\": [], \"time\": []}\n",
    "}\n",
    "\n",
    "# Execute each algorithm 10 times\n",
    "for _ in range(10):\n",
    "    # Louvain\n",
    "    start_time = time.time()\n",
    "    communities_louvain = algorithms.louvain(G)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Louvain\"][\"modularity\"].append(communities_louvain.newman_girvan_modularity().score)\n",
    "    results[\"Louvain\"][\"communities\"].append(len(communities_louvain.communities))\n",
    "    results[\"Louvain\"][\"time\"].append(elapsed_time)\n",
    "    \n",
    "    # Leiden\n",
    "    start_time = time.time()\n",
    "    partition = leidenalg.find_partition(g, partition_type=leidenalg.ModularityVertexPartition, weights='weight')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results[\"Leiden\"][\"modularity\"].append(partition.modularity)\n",
    "    results[\"Leiden\"][\"communities\"].append(len(partition))\n",
    "    results[\"Leiden\"][\"time\"].append(elapsed_time)\n",
    "\n",
    "# Calculate averages\n",
    "for method in results:\n",
    "    results[method][\"avg_modularity\"] = np.mean(results[method][\"modularity\"])\n",
    "    results[method][\"avg_time\"] = np.mean(results[method][\"time\"])\n",
    "    results[method][\"avg_communities\"] = np.mean(results[method][\"communities\"])\n",
    "\n",
    "# Print or store the results as needed\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Louvain': {'modularity': [0.7107906293333608, 0.7146033550336707, 0.7100781811219058, 0.711286922818838, 0.7104126879038287, 0.7107213783426581, 0.7112670943582213, 0.7140453817597964, 0.7109466649870047, 0.7102647930672743], 'communities': [270, 407, 323, 317, 276, 314, 346, 131, 271, 378], 'time': [140.05474710464478, 185.6614499092102, 155.41062927246094, 143.72338771820068, 165.8080689907074, 114.40305089950562, 145.0077781677246, 146.19717693328857, 183.72993516921997, 167.2318778038025], 'avg_modularity': 0.7114417088726559, 'avg_time': 154.72281019687654, 'avg_communities': 303.3}, 'Leiden': {'modularity': [0.6061964131056568, 0.6077849209284348, 0.6039175958946954, 0.6085297553859685, 0.6031347141821898, 0.6097619507061808, 0.6060376328682938, 0.6013012777554784, 0.6025305536021106, 0.6052087022958809], 'communities': [314, 291, 282, 219, 382, 246, 307, 287, 348, 254], 'time': [15.384473085403442, 16.508063793182373, 15.92988896369934, 17.097694158554077, 16.93193292617798, 17.44502305984497, 15.634144067764282, 16.402777194976807, 16.290759801864624, 16.788152933120728], 'avg_modularity': 0.605440351672489, 'avg_time': 16.44129099845886, 'avg_communities': 293.0}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Algorithm  Run  Modularity  Communities    Time (s)\n",
      "0    Louvain    1    0.710791          270  140.054747\n",
      "1    Louvain    2    0.714603          407  185.661450\n",
      "2    Louvain    3    0.710078          323  155.410629\n",
      "3    Louvain    4    0.711287          317  143.723388\n",
      "4    Louvain    5    0.710413          276  165.808069\n",
      "5    Louvain    6    0.710721          314  114.403051\n",
      "6    Louvain    7    0.711267          346  145.007778\n",
      "7    Louvain    8    0.714045          131  146.197177\n",
      "8    Louvain    9    0.710947          271  183.729935\n",
      "9    Louvain   10    0.710265          378  167.231878\n",
      "10    Leiden    1    0.606196          314   15.384473\n",
      "11    Leiden    2    0.607785          291   16.508064\n",
      "12    Leiden    3    0.603918          282   15.929889\n",
      "13    Leiden    4    0.608530          219   17.097694\n",
      "14    Leiden    5    0.603135          382   16.931933\n",
      "15    Leiden    6    0.609762          246   17.445023\n",
      "16    Leiden    7    0.606038          307   15.634144\n",
      "17    Leiden    8    0.601301          287   16.402777\n",
      "18    Leiden    9    0.602531          348   16.290760\n",
      "19    Leiden   10    0.605209          254   16.788153\n",
      "  Algorithm  Avg. Modularity  Avg. Communities  Avg. Time (s)\n",
      "0   Louvain         0.711442             303.3     154.722810\n",
      "1    Leiden         0.605440             293.0      16.441291\n"
     ]
    }
   ],
   "source": [
    "# Convert the results dictionary into a pandas DataFrame\n",
    "# First, prepare the data in a structured form\n",
    "data = {\n",
    "    \"Algorithm\": [],\n",
    "    \"Run\": [],\n",
    "    \"Modularity\": [],\n",
    "    \"Communities\": [],\n",
    "    \"Time (s)\": []\n",
    "}\n",
    "\n",
    "# Populate the structured data from the results\n",
    "for algo in results:\n",
    "    for run in range(10):  # Assuming 10 runs as previously set\n",
    "        data[\"Algorithm\"].append(algo)\n",
    "        data[\"Run\"].append(run + 1)  # Run number (1-10)\n",
    "        data[\"Modularity\"].append(results[algo][\"modularity\"][run])\n",
    "        data[\"Communities\"].append(results[algo][\"communities\"][run])\n",
    "        data[\"Time (s)\"].append(results[algo][\"time\"][run])\n",
    "\n",
    "# Creating the DataFrame\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame for visual inspection\n",
    "print(results_df)\n",
    "\n",
    "# Additionally, creating a summary DataFrame for averages\n",
    "summary_data = {\n",
    "    \"Algorithm\": [\"Louvain\", \"Leiden\"],\n",
    "    \"Avg. Modularity\": [results[\"Louvain\"][\"avg_modularity\"], results[\"Leiden\"][\"avg_modularity\"]],\n",
    "    \"Avg. Communities\": [results[\"Louvain\"][\"avg_communities\"], results[\"Leiden\"][\"avg_communities\"]],\n",
    "    \"Avg. Time (s)\": [results[\"Louvain\"][\"avg_time\"], results[\"Leiden\"][\"avg_time\"]]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'M2V_CD_Experiment_Values.csv'\n",
    "results_df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
